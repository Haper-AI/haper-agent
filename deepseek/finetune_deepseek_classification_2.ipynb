{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02aPTGVc_QZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ded3bd-7505-4902-f20a-9b96fca804c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets accelerate peft bitsandbytes torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EvalPrediction, DataCollatorWithPadding, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "ONtyxSaR_pJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
      ],
      "metadata": {
        "id": "XKVWS44oBOu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# json_path = \"/content/drive/MyDrive/Agent/output_cat.jsonl\"\n",
        "# df = pd.read_json(json_path, lines=True)\n",
        "\n",
        "# data = [{\"text\": df[\"messages\"][i][1][\"content\"], \"label\": df[\"messages\"][i][2][\"content\"]} for i in range(len(df))]\n",
        "# with open(\"/content/drive/MyDrive/Agent/output_cat.json\", \"w\") as file:\n",
        "#     json.dump(data, file)"
      ],
      "metadata": {
        "id": "fhE353UGEC6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_path = \"/content/drive/MyDrive/Agent/output_cat.json\"\n",
        "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "df[\"label\"] = df[\"label\"].map({\"Receipt\":0, \"Promotion\":1, \"Education\":2, \"Notice\":3, \"Career Development\":4, \"News\":5})\n",
        "dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXcZLmw-_Xun",
        "outputId": "02b4a1d6-aa76-4255-b3de-c649453a320e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text      label\n",
            "0     Email content:\\nKaggle launched the FGVC12 202...  Education\n",
            "1     Email content:\\nKaggle's BirdCLEF+ 2025 compet...  Education\n",
            "2     Email content:\\nYou received a notification fr...       News\n",
            "3     Email content:\\nKaggle announces the launch of...       News\n",
            "4     Email content:\\nYou purchased \"GEAR UP SPECIAL...    Receipt\n",
            "...                                                 ...        ...\n",
            "1404  Email content:\\nAlan Walker is en route to Aus...       News\n",
            "1405  Email content:\\nTwitter has shared 35 new upda...       News\n",
            "1406  Email content:\\nYou have received 12 notificat...     Notice\n",
            "1407  Email content:\\nTwitter wishes Jasper a bright...       News\n",
            "1408  Email content:\\nYou have received 8 Twitter no...     Notice\n",
            "\n",
            "[1409 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split[\"train\"]\n",
        "test_dataset = train_test_split[\"test\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334,
          "referenced_widgets": [
            "115572ea0d874e76b38ef45eda19558d",
            "fbfff53f50e9406ea812a8453aa8f035",
            "86c118f51ff041b3a2aa44bbadc517fb",
            "57948f7c81184bdd8e4e119070046006",
            "05efebd7cd3c442887ae64db912a0287",
            "e714a0303eb84c6a939e60a0c9f1921e",
            "d9c07b9bb4474198b17b3bb4dcaa2ed5",
            "06f9699bc35241f5a2dd774f7168d461",
            "8a0970069f6145d598b9e6e0571218ab",
            "ba38db4cabe6466895db7016362dd686",
            "9273c81999be4231b457b98f107347b1",
            "97750a3a55624012b308c2fc5f67c9ba",
            "4bd3d6888a6e4be89f358245e6568ea9",
            "f54fa2ce61f647068cd81da797b69f1a",
            "cb4c8f3e18e444f6a030b187eaa9765d",
            "039ce0555f474b549b8f59fb12019a05",
            "250a0bc0c09c4004ad9eab0b1a006aad",
            "51104ae667864b55bc1504b1de11df02",
            "57efc359d33e48f69cd04485bf7e9171",
            "7be976257eb44f2191b24c7a398b9a47",
            "90547f21e09e4d799f29fa64f395fa76",
            "893a74815c4247139e51c67d02af5e29",
            "b602cd7ea40e473bb84372f603385c47",
            "289ea8c12e364ef7942ee2ec0cbc7bea",
            "a6b8eedb3a0e4c2b95658cc39f16cb49",
            "418306c664484b01bbc2b0a2e70ece53",
            "bc453644248a4d35aa92043c05ec8199",
            "e66a20081b724d38900d4da8e8f2bc90",
            "26a29db8be2b4bc6aa2b094aa4c062b6",
            "72d583fc96774b878381bcd6ccd3e6b6",
            "1757546c484a4f05a53162a352a1c702",
            "228336df11534561a4cba0005f41273b",
            "2dd74ed8cb934badbb8d49f9522560ef",
            "fd7e04242f674b4ba02c434272bcf8c2",
            "710883b38dab47f7afd250560f2027a7",
            "76fb948e8ae54c7e890ab3b6ab8550cf",
            "2086afaa559f40c09fd6a6f2922ebc30",
            "e1ee1376b5e74ef1b5a67c1a4f9dfecb",
            "40027f8345f04ef698d67f26e42bb956",
            "8c3177762cf04d66bd23ad43885c1a72",
            "30eca7633235460886c27d26f1e5d6a4",
            "efce79fc3a634882be3878baa1d47ad0",
            "9d5ad60b628e4c639bbc50daeb603081",
            "70eedbae83fd48cea079afdb0317ba6e",
            "a51c4ae7684d42c5becfa45abc9924ad",
            "0160bd33074a4ab4b47c8cb633bb4eb0",
            "8ecf3d916c394163947cf31e2b4108bc",
            "42d4c98d9bf14848ad080ea1270deec2",
            "7a54e7b1e5df4ebd9e5d4bbe9630cdd9",
            "d77ffea69d5e4c0abfb5303dac27b5c5",
            "1e9665026d9b44ebbb0e7ce97c20b723",
            "07ea05cef2ff44ff9f3504c106f9850f",
            "222361c9aaa845239525f61d371a806c",
            "c518a6abe2b34bda925b29adff3dfcf4",
            "dde97e3960e04b4a8588e0b347c773e1",
            "2f8bb92ee122445098ee5b6185729678",
            "d2d966498ae346018c0798f671a93e3a",
            "395a68ae87514bef9375af458df4edae",
            "15518d0a33b84dc8805776c158bfb565",
            "4d42356c3a2f4146bb46ebb85e83b612",
            "e225d8c28f7640548427509040deadd5",
            "a7fd5913a4014ca39d279879b16d3060",
            "241569d5acc54077bdf1380f49ad35b5",
            "d70512a2261841b1a3005d8a38fdaaec",
            "0c9419f99eb84ca8b429079c4f93f40f",
            "acf8bce2e85f4b91a7d70606a5b78ccf"
          ]
        },
        "id": "MQMzZFVrBkCg",
        "outputId": "768cd46f-bedc-41a0-9d01-6dcbd9d1f523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "115572ea0d874e76b38ef45eda19558d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97750a3a55624012b308c2fc5f67c9ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b602cd7ea40e473bb84372f603385c47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd7e04242f674b4ba02c434272bcf8c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a51c4ae7684d42c5becfa45abc9924ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1409 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f8bb92ee122445098ee5b6185729678"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset)\n",
        "print(len(train_dataset[0]['input_ids']))\n",
        "print(len(train_dataset[1]['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5HGRNkhBwF9",
        "outputId": "5a9ae99d-b15d-4ce9-8424-95cc291388f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 282\n",
            "})\n",
            "512\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -q -y bitsandbytes\n",
        "!pip install -q -U bitsandbytes transformers accelerate"
      ],
      "metadata": {
        "id": "g4ewoVVrGWNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88daab0f-449b-48b9-a3fa-c849ee93e3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=\"float16\", bnb_4bit_use_double_quant=True)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    # quantization_config=bnb_config,\n",
        "    num_labels=6,\n",
        "    device_map=\"auto\",\n",
        "    max_memory={0: \"12GB\", \"cpu\": \"16GB\"}\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "lora_config = LoraConfig(r=16, lora_alpha=32, lora_dropout=0.1, target_modules=[\"q_proj\", \"v_proj\"], bias=\"none\")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./qlora_deepseek\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=20,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    label_names=[\"labels\"],\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"tensorboard\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=1,\n",
        "    eval_steps=1,\n",
        "    fp16=True,\n",
        "    optim=\"adamw_torch\",\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    eval_accuracy = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": eval_accuracy}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "wlnSOddoCU0F",
        "outputId": "4d209e5c-1684-4b49-b051-255cc3ceb2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,179,072 || all params: 1,545,902,592 || trainable%: 0.1410\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1400' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1400/1400 1:24:56, Epoch 19/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.266200</td>\n",
              "      <td>0.759591</td>\n",
              "      <td>0.748227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.279500</td>\n",
              "      <td>0.406109</td>\n",
              "      <td>0.890071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.376244</td>\n",
              "      <td>0.897163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>0.391314</td>\n",
              "      <td>0.886525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.424945</td>\n",
              "      <td>0.900709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.540795</td>\n",
              "      <td>0.879433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.420268</td>\n",
              "      <td>0.907801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.519664</td>\n",
              "      <td>0.893617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.496635</td>\n",
              "      <td>0.904255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.518588</td>\n",
              "      <td>0.900709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.523887</td>\n",
              "      <td>0.897163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.533951</td>\n",
              "      <td>0.897163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.539122</td>\n",
              "      <td>0.897163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.545708</td>\n",
              "      <td>0.897163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.549919</td>\n",
              "      <td>0.900709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.551730</td>\n",
              "      <td>0.900709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.555008</td>\n",
              "      <td>0.900709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.557319</td>\n",
              "      <td>0.904255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.557970</td>\n",
              "      <td>0.900709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1400, training_loss=0.10638200921119798, metrics={'train_runtime': 5102.5034, 'train_samples_per_second': 4.417, 'train_steps_per_second': 0.274, 'total_flos': 8.962930123525325e+16, 'train_loss': 0.10638200921119798, 'epoch': 19.72340425531915})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ],
      "metadata": {
        "id": "iRJhSINeDZuI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "378f8f07-e992-4a90-e9d5-35aaa5f47122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='142' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [71/71 01:28]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.42026832699775696, 'eval_accuracy': 0.9078014184397163, 'eval_runtime': 26.8496, 'eval_samples_per_second': 10.503, 'eval_steps_per_second': 2.644, 'epoch': 19.72340425531915}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/Agent\")"
      ],
      "metadata": {
        "id": "yTJPqz9sGIbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load the model\n",
        "\n",
        "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Agent/finetune_deepseek_classification_2\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Agent/finetune_deepseek_classification_2\")"
      ],
      "metadata": {
        "id": "ijgKss1DTIve"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
